{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK2qx16izkiP"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0k6i1pf2FQG"
      },
      "source": [
        "#Pytorch on CIFAR-10 Dataset with Batch Normalisation and Dropout on Convolution Layers output after the activation function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExUAxsshF398",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# # Install torchvision\n",
        "# !pip3 install torch==1.2.0+cu92 torchvision==0.4.0+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EY1oIBQPJzLn"
      },
      "outputs": [],
      "source": [
        "'''ResNet in PyTorch.\n",
        "Reference:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition.\n",
        "[2] https://github.com/kuangliu/pytorch-cifar\n",
        "[3] https://github.com/abhisikdar/RESNET18-CIFAR10 \n",
        "[4] https://www.srose.biz/wp-content/uploads/2020/08/Batch-Size-and-Epochs.html  \n",
        "'''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        \n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "        # Dropout after Convolutional BasicBlock\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.dropout(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.randn(1, 3, 32, 32))\n",
        "    print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3vJfiujKAA8",
        "outputId": "3899f615-7b59-4c45-93db-cc5d1c8fc4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is CUDA available True\n",
            "Torch 2.0.0+cu118 CUDA 11.8\n",
            "Device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "print('Is CUDA available', torch.cuda.is_available())\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bl1ayyQoV12D"
      },
      "source": [
        "# Data Pre-processing</br>\n",
        "1. Random cropping, with size 32x32 and padding 4</br>\n",
        "2. Random horizontal flipping with a probability of 0.5</br>\n",
        "3. Normalize each image’s RGB channel with mean() and std()</br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Q8yZoewbH-c",
        "outputId": "75a97a51-f052-4d89-fbf8-599f757395b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:06<00:00, 28370547.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "data_path='../data/'\n",
        "cifar=datasets.CIFAR10(data_path, train= True, download=True, transform=transforms.ToTensor())\n",
        "cifar_val=datasets.CIFAR10(data_path, train=False, download= True, transform=transforms.ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaEu9XyAbQnA",
        "outputId": "7d7e0498-cedc-4a8b-be6c-c6358c66192e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the CIFAR stack is torch.Size([3, 32, 32, 50000])\n",
            "Mean of training data is tensor([0.4914, 0.4822, 0.4465])\n",
            "Standard deviation of training data is tensor([0.2470, 0.2435, 0.2616])\n"
          ]
        }
      ],
      "source": [
        "cifar_stack = torch.stack([img for img, _ in cifar], dim=3)\n",
        "print('Shape of the CIFAR stack is',cifar_stack.shape)\n",
        "mean= cifar_stack.view(3,-1).mean(dim=1)\n",
        "std= cifar_stack.view(3,-1).std(dim=1)\n",
        "print('Mean of training data is', mean)\n",
        "print('Standard deviation of training data is', std)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gFxMI-jGbkuZ"
      },
      "outputs": [],
      "source": [
        "cifar_transformed = datasets.CIFAR10(data_path,train=True,download=False, transform=transforms.Compose([\n",
        "                                                                                                      transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),transforms.ToTensor(),transforms.Normalize(mean,std)\n",
        "]))\n",
        "cifar_val_transformed = datasets.CIFAR10(data_path,train=False,download=False, transform=transforms.Compose([\n",
        "                                                                                                      transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),transforms.ToTensor(),transforms.Normalize(mean,std)\n",
        "]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "OEPqKwgmbecl",
        "outputId": "c363debf-f42b-4c83-9207-9e93f6a82ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# View images\n",
        "\n",
        "img, label = cifar_transformed[28]\n",
        "plt.imshow(img.permute(1, 2, 0))    \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3bOnutot4Q6"
      },
      "source": [
        "#Varied the batch size for training dataset with other parameters fixed to measure the effect of batch size.</br>\n",
        "Now, our Data is ready for Training.</br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "840E6DAybjuM"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "batch_size=[256,512]\n",
        "val_batch_size=100\n",
        "num_epochs=80\n",
        "# learning_rate=0.1\n",
        "\n",
        "dev=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "max_validation = 0\n",
        "max_epoch=0\n",
        "val_acc=[]\n",
        "train_acc=[]\n",
        "epochs=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "avav9Xfgd5-B"
      },
      "outputs": [],
      "source": [
        "for batch_no in range(len(batch_size)):\n",
        "  # Train/Test Data\n",
        "  train_loader=torch.utils.data.DataLoader(cifar_transformed,batch_size=batch_size[batch_no],shuffle=True, num_workers=4)\n",
        "  train_acc_loader=torch.utils.data.DataLoader(cifar_transformed,batch_size=val_batch_size,shuffle=False, num_workers=4)\n",
        "  val_loader = torch.utils.data.DataLoader(cifar_val_transformed, batch_size=val_batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "  # Model\n",
        "  resnet18 =ResNet18()\n",
        "  resnet18=resnet18.to(dev)\n",
        "  loss_func= torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(resnet18.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "  for i in range(num_epochs):\n",
        "    # Training\n",
        "    for imgs, labels in train_loader:\n",
        "      if dev is not None:\n",
        "        imgs,labels=imgs.to(dev),labels.to(dev)\n",
        "      out= resnet18(imgs)\n",
        "      loss=loss_func(out,labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    correct_train_acc=0\n",
        "    total_train_acc=0\n",
        "    # Testing\n",
        "    with torch.no_grad():\n",
        "      for imgs, labels in val_loader:\n",
        "        if dev is not None:\n",
        "          imgs,labels=imgs.to(dev),labels.to(dev)\n",
        "        outputs = resnet18(imgs) \n",
        "        _, predicted = torch.max(outputs, dim=1) \n",
        "        total_val += labels.shape[0]\n",
        "        correct_val += int((predicted == labels).sum())\n",
        "      val_acc.append(correct_val/total_val)\n",
        "\n",
        "    # Compute Loss and Accuracy on training data\n",
        "      for train_acc_imgs,train_acc_labels in train_acc_loader:\n",
        "        if dev is not None:\n",
        "          train_acc_imgs,train_acc_labels=train_acc_imgs.to(dev),train_acc_labels.to(dev)\n",
        "        train_acc_out=resnet18(train_acc_imgs)\n",
        "        _, train_acc_predicted = torch.max(train_acc_out, dim=1)\n",
        "        total_train_acc += train_acc_labels.shape[0]\n",
        "        correct_train_acc += int((train_acc_predicted == train_acc_labels).sum())\n",
        "        # minibatch_acc = accuracy(train_acc, train_acc_labels,1)[0]\n",
        "        # print(\"Top-1 training accuracy for minibatch\", minibatch_acc)\n",
        "      train_acc.append(correct_train_acc/total_train_acc)\n",
        "      \n",
        "      \n",
        "      if correct_val/total_val > max_validation:\n",
        "        max_validation=correct_val/total_val\n",
        "        max_epoch=i\n",
        "        torch.save(resnet18,'./scratch.pt' )\n",
        "    epochs.append(i)\n",
        "\n",
        "    \n",
        "\n",
        "    if i%1==0:\n",
        "      print(\"Epoch no %d:\\t Train Loss: %f \\t Train Accuracy: %f \\t Validation Accuracy: %f\" % (i+1, float(loss), correct_train_acc / total_train_acc, correct_val / total_val))\n",
        "      # print(\"Train Accuracy: \", correct_train_acc / total_train_acc)\n",
        "      # print(\"Validation Accuracy: \", correct_val / total_val)\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "  print(max_validation)\n",
        "\n",
        "  # Plot Train Accuracy vs Test Accuracy\n",
        "  plt.plot(epochs, val_acc, label=\"Accuracy Test\", color=\"yellow\", linestyle='-')\n",
        "  plt.plot(epochs, train_acc, label=\"Accuracy Train\", color=\"red\",linestyle=':')\n",
        "  plt.scatter([max_epoch], [max_validation],color=\"blue\", marker=\"#\", label=\"Maximum Value\", s=100 )\n",
        "  plt.title(\"Batch Size Model\")\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LslVlS_wMTH"
      },
      "source": [
        "#Varied the no of epochs with a fixed batch size to measure the effect of varying the epoch size.</br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KQPLlOpwmED"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "batch_size=512\n",
        "val_batch_size=100\n",
        "num_epochs=[100,120]\n",
        "# learning_rate=2*1e-3\n",
        "\n",
        "dev=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "max_validation = 0\n",
        "max_epoch=0\n",
        "val_acc=[]\n",
        "train_acc=[]\n",
        "epochs=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-0Q_Wy0wsPo"
      },
      "outputs": [],
      "source": [
        "for epoch_no in range(len(num_epochs)):\n",
        "  # Train/Test Data\n",
        "  train_loader=torch.utils.data.DataLoader(cifar_transformed,batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  train_acc_loader=torch.utils.data.DataLoader(cifar_transformed,batch_size=val_batch_size,shuffle=False, num_workers=4)\n",
        "  val_loader = torch.utils.data.DataLoader(cifar_val_transformed, batch_size=val_batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "  # Model\n",
        "  resnet18 =ResNet18()\n",
        "  resnet18=resnet18.to(dev)\n",
        "  loss_func= torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(resnet18.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "  for i in range(num_epochs[epoch_no]):\n",
        "    # Training\n",
        "    for imgs, labels in train_loader:\n",
        "      if dev is not None:\n",
        "        imgs,labels=imgs.to(dev),labels.to(dev)\n",
        "      out= resnet18(imgs)\n",
        "      loss=loss_func(out,labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    correct_train_acc=0\n",
        "    total_train_acc=0\n",
        "    # Testing\n",
        "    with torch.no_grad():\n",
        "      for imgs, labels in val_loader:\n",
        "        if dev is not None:\n",
        "          imgs,labels=imgs.to(dev),labels.to(dev)\n",
        "        outputs = resnet18(imgs) \n",
        "        _, predicted = torch.max(outputs, dim=1) \n",
        "        total_val += labels.shape[0]\n",
        "        correct_val += int((predicted == labels).sum())\n",
        "      val_acc.append(correct_val/total_val)\n",
        "\n",
        "    # Compute Loss and Accuracy on training data\n",
        "      for train_acc_imgs,train_acc_labels in train_acc_loader:\n",
        "        if dev is not None:\n",
        "          train_acc_imgs,train_acc_labels=train_acc_imgs.to(dev),train_acc_labels.to(dev)\n",
        "        train_acc_out=resnet18(train_acc_imgs)\n",
        "        _, train_acc_predicted = torch.max(train_acc_out, dim=1)\n",
        "        total_train_acc += train_acc_labels.shape[0]\n",
        "        correct_train_acc += int((train_acc_predicted == train_acc_labels).sum())\n",
        "        # minibatch_acc = accuracy(train_acc, train_acc_labels,1)[0]\n",
        "        # print(\"Top-1 training accuracy for minibatch\", minibatch_acc)\n",
        "      train_acc.append(correct_train_acc/total_train_acc)\n",
        "      \n",
        "      \n",
        "      if correct_val/total_val > max_validation:\n",
        "        max_validation=correct_val/total_val\n",
        "        max_epoch=i\n",
        "    epochs.append(i)\n",
        "\n",
        "    \n",
        "\n",
        "    if i%1==0:\n",
        "      print(\"Epoch no %d:\\t Train Loss: %f \\t Train Accuracy: %f \\t Validation Accuracy: %f\" % (i+1, float(loss), correct_train_acc / total_train_acc, correct_val / total_val))\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "  print(max_validation)\n",
        "\n",
        "  # Plot Train Accuracy vs Test Accuracy\n",
        "  plt.plot(epochs, val_acc, label=\"Accuracy Test\", color=\"yellow\", linestyle='-')\n",
        "  plt.plot(epochs, train_acc, label=\"Accuracy Train\", color=\"red\",linestyle=':')\n",
        "  plt.scatter([max_epoch], [max_validation],color=\"blue\", marker=\"#\", label=\"The Maximum Value\", s=100 )\n",
        "  plt.title(\"Varying Epochs Model\")\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiBkSYZQ0u95"
      },
      "source": [
        "#Varied the learning rate [0.1, 0.01, 0.001, 0.0001] on fixed batch size and fixed no of epoch to observe the effect of varying the epoch size</br>\n",
        "Results for lr = 0.1 have been shown above  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqiN7lbP0vbm"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "batch_size=512\n",
        "val_batch_size=100\n",
        "num_epochs=100\n",
        "learning_rate=[0.01, 0.001, 0.0001]\n",
        "\n",
        "dev=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "max_validation = 0\n",
        "max_epoch=0\n",
        "val_acc=[]\n",
        "train_acc=[]\n",
        "epochs=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lR8bSdzT0wD9"
      },
      "outputs": [],
      "source": [
        "for lr_no in range(len(learning_rate)):\n",
        "  # Train/Test Data\n",
        "  train_loader=torch.utils.data.DataLoader(cifar_transformed,batch_size=batch_size,shuffle=True, num_workers=4)\n",
        "  train_acc_loader=torch.utils.data.DataLoader(cifar_transformed,batch_size=val_batch_size,shuffle=False, num_workers=4)\n",
        "  val_loader = torch.utils.data.DataLoader(cifar_val_transformed, batch_size=val_batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "  # Model\n",
        "  resnet18 =ResNet18()\n",
        "  resnet18=resnet18.to(dev)\n",
        "  loss_func= torch.nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(resnet18.parameters(), lr=learning_rate[lr_no], momentum=0.9, weight_decay=5e-4)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "\n",
        "  for i in range(num_epochs):\n",
        "    # Training\n",
        "    for imgs, labels in train_loader:\n",
        "      if dev is not None:\n",
        "        imgs,labels=imgs.to(dev),labels.to(dev)\n",
        "      out= resnet18(imgs)\n",
        "      loss=loss_func(out,labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    \n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    correct_train_acc=0\n",
        "    total_train_acc=0\n",
        "    # Testing\n",
        "    with torch.no_grad():\n",
        "      for imgs, labels in val_loader:\n",
        "        if dev is not None:\n",
        "          imgs,labels=imgs.to(dev),labels.to(dev)\n",
        "        outputs = resnet18(imgs) \n",
        "        _, predicted = torch.max(outputs, dim=1) \n",
        "        total_val += labels.shape[0]\n",
        "        correct_val += int((predicted == labels).sum())\n",
        "      val_acc.append(correct_val/total_val)\n",
        "\n",
        "    # Compute Loss and Accuracy on training data\n",
        "      for train_acc_imgs,train_acc_labels in train_acc_loader:\n",
        "        if dev is not None:\n",
        "          train_acc_imgs,train_acc_labels=train_acc_imgs.to(dev),train_acc_labels.to(dev)\n",
        "        train_acc_out=resnet18(train_acc_imgs)\n",
        "        _, train_acc_predicted = torch.max(train_acc_out, dim=1)\n",
        "        total_train_acc += train_acc_labels.shape[0]\n",
        "        correct_train_acc += int((train_acc_predicted == train_acc_labels).sum())\n",
        "        # minibatch_acc = accuracy(train_acc, train_acc_labels,1)[0]\n",
        "        # print(\"Top-1 training accuracy for minibatch\", minibatch_acc)\n",
        "      train_acc.append(correct_train_acc/total_train_acc)\n",
        "      \n",
        "      \n",
        "      if correct_val/total_val > max_validation:\n",
        "        max_validation=correct_val/total_val\n",
        "        max_epoch=i\n",
        "    epochs.append(i)\n",
        "\n",
        "    \n",
        "\n",
        "    if i%1==0:\n",
        "      print(\"Epoch no %d:\\t Train Loss: %f \\t Train Accuracy: %f \\t Validation Accuracy: %f\" % (i+1, float(loss), correct_train_acc / total_train_acc, correct_val / total_val))\n",
        "    \n",
        "    scheduler.step()\n",
        "\n",
        "  print(max_validation)\n",
        "\n",
        "  # Plot Train Accuracy vs Test Accuracy\n",
        "  plt.plot(epochs, val_acc, label=\"Accuracy Test\", color=\"yellow\", linestyle='-')\n",
        "  plt.plot(epochs, train_acc, label=\"Accuracy Train\", color=\"red\",linestyle=':')\n",
        "  plt.scatter([max_epoch], [max_validation],color=\"blue\", marker=\"#\", label=\"Maximum value\", s=100 )\n",
        "  plt.title(\"Varying Learning Rate Model\")\n",
        "  plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}